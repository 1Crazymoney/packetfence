// to display images directly on GitHub
ifdef::env-github[]
:encoding: UTF-8
:lang: en
:doctype: book
:toc: left
:imagesdir: ../images
endif::[]

////

    This file is part of the PacketFence project.

    See PacketFence_Clustering_Guide.asciidoc
    for authors, copyright and license information.

////

//== Troubleshooting a cluster

=== Checking the MariaDB sync

In order to check the MariaDB sync, you can look at the status of the `wsrep` status values inside MariaDB.

----
MariaDB> show status like 'wsrep%';
----

Important variables:

  * `wsrep_cluster_status`: Display whether or not the node is part of a primary view or not. A healthy cluster should always show as primary
  * `wsrep_incoming_addresses`: The current members of the cluster. All the nodes of your cluster should be listed there.
  * `wsrep_local_state_comment`: Current sync state of the cluster. A healthy state is 'Synced'. Refer to the Galera cluster documentation for the meaning of the other values this can have.

In order for the cluster to be considered healthy, all nodes must be listed under `wsrep_incoming_addresses` and `wsrep_local_state_comment` must be `Synced`. Otherwise look in the MariaDB log ([filename]`/usr/local/pf/logs/mariadb_error.log`)

=== Rejoining a node to an existing cluster

When only one node has left cluster, you can apply following commands on that node to rejoin:

[source,bash]
----
systemctl stop packetfence-mariadb
systemctl stop packetfence-galera-autofix
rm -fr /var/lib/mysql/*
systemctl start packetfence-mariadb
systemctl start packetfence-galera-autofix
----

This action will not cause service disruption on current cluster.

=== Recovering when a node is missing

If one of the nodes cannot recover, you can manually reset the cluster state. Note that this procedure is only valid if all the nodes were hard-shutdown at the same time.

First, stop `packetfence-mariadb` on all servers:

  # systemctl stop packetfence-mariadb

Then remove `/var/lib/mysql/gvwstate.dat` on all the servers that are still alive.

Next, see the section 'Recovering from a split brain' to start up a new cluster.

=== Recovering from a split brain

If you leave the cluster in auto-recovery mode without electing a master manually, the structure of the cluster is made so that a split-brain can never occur since a server will fallback in read-only if it can't join a primary view (quorum).

Should you decide to elect a new master and cause a split-brain for crash recovery purpose, you will have to wipe the data on all the servers that are part of one side of the split brain. This should be done once all the servers have re-gained communication.

=== Full recovery

If you want to perform a full recovery which can be necessary after experiencing an issue with Galera cluster, you must stop the node you wish to keep the data from and start it with the `--force-new-cluster` option. If this is not the case, you can continue onto the next step

  # systemctl stop packetfence-mariadb
  # /usr/local/pf/sbin/pf-mariadb --force-new-cluster

==== On each of the discarded servers

First, stop packetfence-mariadb on *all* the servers you want to discard data from.

  systemctl stop packetfence-mariadb

On each of the servers you want to discard the data from, you must destroy all the data in `/var/lib/mysql` and start `packetfence-mariadb` so it resyncs its data from scratch.

  rm -fr /var/lib/mysql/*
  systemctl start packetfence-mariadb

You should then see `/var/lib/mysql` be populated again with the data and once MariaDB becomes available again on the server, it means the sync has completed. In case of issues, look in the MariaDB log file (`/usr/local/pf/logs/mariadb_error.log`)

NOTE: If you were performing a full recovery, you should now break the `--force-new-cluster` command and start `packetfence-mariadb` normally. (`systemctl start packetfence-mariadb`)

=== Putting a node in maintenance

When doing maintenance on a node (especially the management node), it is always better to put it in maintenance mode so it doesn't try to join an existing cluster.

In order to activate the maintenance mode on a node:

  # /usr/local/pf/bin/cluster/maintenance --activate

In order to deactivate the maintenance mode on a node:

  # /usr/local/pf/bin/cluster/maintenance --deactivate

In order to see the current maintenance state on a node:

  # /usr/local/pf/bin/cluster/maintenance
